#!/usr/bin/env python3
"""
GitHub Release to Cloudflare R2 Sync Script
ä»æŒ‡å®šçš„GitHubé¡¹ç›®è·å–æœ€æ–°releaseå¹¶åŒæ­¥åˆ°Cloudflare R2
æ”¯æŒå…¬å…±ä»“åº“çš„åŒ¿åè®¿é—®
"""

import os
import sys
import yaml
import json
import logging
import requests
import boto3
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from urllib.parse import urlparse
from fnmatch import fnmatch
from tqdm import tqdm
import tempfile
import hashlib
from datetime import datetime
import time


class GitHubAPIClient:
    """GitHub API å®¢æˆ·ç«¯ï¼Œæ”¯æŒåŒ¿åå’Œè®¤è¯è®¿é—®"""

    def __init__(self, token: Optional[str] = None, config: Dict = None):
        self.session = requests.Session()
        self.token = token
        self.config = config or {}
        self.api_limits_config = self.config.get("api_limits", {}).get("github", {})
        self.logger = logging.getLogger(__name__)

        # è®¾ç½®è¯·æ±‚å¤´
        self.session.headers.update(
            {
                "Accept": "application/vnd.github.v3+json",
                "User-Agent": "Release-Sync-Tool/1.0",
            }
        )

        if self.token:
            self.session.headers.update({"Authorization": f"token {self.token}"})
            self.logger.info("ä½¿ç”¨GitHub Tokenè¿›è¡Œè®¤è¯è®¿é—® (5000æ¬¡/å°æ—¶)")
        else:
            self.logger.info("ä½¿ç”¨åŒ¿åè®¿é—®GitHub API (60æ¬¡/å°æ—¶)")

    def get_rate_limit_info(self) -> Dict:
        """è·å–APIé™åˆ¶ä¿¡æ¯"""
        try:
            response = self.session.get("https://api.github.com/rate_limit", timeout=10)
            if response.status_code == 200:
                return response.json()
        except Exception as e:
            self.logger.warning(f"è·å–APIé™åˆ¶ä¿¡æ¯å¤±è´¥: {e}")
        return {}

    def check_rate_limit(self) -> bool:
        """æ£€æŸ¥APIé™åˆ¶"""
        if not self.api_limits_config.get("respect_rate_limit", True):
            return True

        rate_limit_info = self.get_rate_limit_info()
        if not rate_limit_info:
            return True

        core_limit = rate_limit_info.get("rate", {})
        remaining = core_limit.get("remaining", 1)
        reset_time = core_limit.get("reset", 0)

        if remaining <= 5:  # ä¿ç•™5æ¬¡è¯·æ±‚ä½œä¸ºç¼“å†²
            reset_datetime = datetime.fromtimestamp(reset_time)
            wait_seconds = max(0, reset_time - int(time.time()))

            self.logger.warning(
                f"APIé™åˆ¶å³å°†è€—å°½ï¼Œå‰©ä½™: {remaining}ï¼Œé‡ç½®æ—¶é—´: {reset_datetime}"
            )

            if self.api_limits_config.get("retry_on_limit", True) and wait_seconds > 0:
                if wait_seconds <= 3600:  # æœ€å¤šç­‰å¾…1å°æ—¶
                    self.logger.info(f"ç­‰å¾…APIé™åˆ¶é‡ç½®ï¼Œç­‰å¾…æ—¶é—´: {wait_seconds} ç§’")
                    time.sleep(wait_seconds + 10)  # é¢å¤–ç­‰å¾…10ç§’
                    return True
                else:
                    self.logger.error("APIé™åˆ¶é‡ç½®æ—¶é—´è¿‡é•¿ï¼Œè·³è¿‡æœ¬æ¬¡æ‰§è¡Œ")
                    return False
            else:
                return False

        return True

    def make_request(self, url: str, **kwargs) -> Optional[requests.Response]:
        """å‘èµ·APIè¯·æ±‚ï¼Œå¸¦é‡è¯•å’Œé™åˆ¶å¤„ç†"""
        max_retries = self.api_limits_config.get("max_retries", 3)
        backoff_factor = self.api_limits_config.get("backoff_factor", 2)

        for attempt in range(max_retries + 1):
            # æ£€æŸ¥APIé™åˆ¶
            if not self.check_rate_limit():
                return None

            try:
                response = self.session.get(url, timeout=30, **kwargs)

                # å¤„ç†ä¸åŒçš„å“åº”çŠ¶æ€
                if response.status_code == 200:
                    return response
                elif response.status_code == 403:
                    # å¯èƒ½æ˜¯APIé™åˆ¶
                    if "rate limit" in response.text.lower():
                        self.logger.warning("é‡åˆ°APIé™åˆ¶ï¼Œå°è¯•ç­‰å¾…...")
                        if attempt < max_retries:
                            wait_time = (backoff_factor**attempt) * 60
                            time.sleep(wait_time)
                            continue
                    else:
                        self.logger.error(f"APIè®¿é—®è¢«ç¦æ­¢: {response.text}")
                        return None
                elif response.status_code == 404:
                    self.logger.error(f"èµ„æºä¸å­˜åœ¨: {url}")
                    return None
                else:
                    response.raise_for_status()

            except requests.RequestException as e:
                self.logger.warning(
                    f"è¯·æ±‚å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries + 1}): {e}"
                )
                if attempt < max_retries:
                    wait_time = (backoff_factor**attempt) * 5
                    time.sleep(wait_time)
                    continue
                else:
                    self.logger.error(f"è¯·æ±‚æœ€ç»ˆå¤±è´¥: {url}")
                    return None

        return None


class ReleaseSync:
    def __init__(self, config_path: str = "config.yaml"):
        """åˆå§‹åŒ–åŒæ­¥å™¨"""
        self.config = self.load_config(config_path)
        self.setup_logging()
        self.setup_clients()

    def load_config(self, config_path: str) -> Dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(config_path, "r", encoding="utf-8") as f:
                return yaml.safe_load(f)
        except FileNotFoundError:
            print(f"é…ç½®æ–‡ä»¶ {config_path} ä¸å­˜åœ¨")
            sys.exit(1)
        except yaml.YAMLError as e:
            print(f"é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
            sys.exit(1)

    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        log_level = getattr(
            logging, self.config.get("settings", {}).get("log_level", "INFO")
        )
        logging.basicConfig(
            level=log_level,
            format="%(asctime)s - %(levelname)s - %(message)s",
            handlers=[
                logging.StreamHandler(),
                logging.FileHandler("sync_releases.log", encoding="utf-8"),
            ],
        )
        self.logger = logging.getLogger(__name__)

    def setup_clients(self):
        """è®¾ç½®å®¢æˆ·ç«¯"""
        # GitHub API å®¢æˆ·ç«¯
        github_token = self.config.get("github", {}).get("token")
        self.github_client = GitHubAPIClient(github_token, self.config)

        # Cloudflare R2 å®¢æˆ·ç«¯
        r2_config = self.config["cloudflare"]
        self.r2_client = boto3.client(
            "s3",
            endpoint_url=r2_config["endpoint_url"],
            aws_access_key_id=r2_config["access_key_id"],
            aws_secret_access_key=r2_config["secret_access_key"],
            region_name="auto",
        )
        self.bucket_name = r2_config["bucket_name"]

    def get_latest_release(self, owner: str, repo: str) -> Optional[Dict]:
        """è·å–æœ€æ–°releaseä¿¡æ¯"""
        url = f"https://api.github.com/repos/{owner}/{repo}/releases/latest"

        self.logger.info(f"è·å– {owner}/{repo} çš„æœ€æ–°release...")

        response = self.github_client.make_request(url)
        if response and response.status_code == 200:
            return response.json()
        else:
            self.logger.error(f"è·å– {owner}/{repo} æœ€æ–°releaseå¤±è´¥")
            return None

    def filter_assets(
        self, assets: List[Dict], pattern: Optional[str] = None
    ) -> List[Dict]:
        """æ ¹æ®æ¨¡å¼è¿‡æ»¤assets"""
        if not pattern:
            return assets

        filtered_assets = []
        for asset in assets:
            if fnmatch(asset["name"], pattern):
                filtered_assets.append(asset)

        self.logger.info(
            f"ä½¿ç”¨æ¨¡å¼ '{pattern}' è¿‡æ»¤ï¼ŒåŒ¹é… {len(filtered_assets)}/{len(assets)} ä¸ªæ–‡ä»¶"
        )
        return filtered_assets

    def file_exists_in_r2(self, key: str) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨äºR2"""
        try:
            self.r2_client.head_object(Bucket=self.bucket_name, Key=key)
            return True
        except self.r2_client.exceptions.NoSuchKey:
            return False
        except Exception as e:
            self.logger.warning(f"æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§æ—¶å‡ºé”™: {e}")
            return False

    def calculate_file_hash(self, file_path: str) -> str:
        """è®¡ç®—æ–‡ä»¶SHA256å“ˆå¸Œ"""
        sha256_hash = hashlib.sha256()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                sha256_hash.update(chunk)
        return sha256_hash.hexdigest()

    def download_asset(self, asset: Dict, target_path: str) -> Optional[str]:
        """ä¸‹è½½assetåˆ°ä¸´æ—¶æ–‡ä»¶"""
        download_url = asset["browser_download_url"]
        filename = asset["name"]
        file_size = asset.get("size", 0)

        self.logger.info(f"å¼€å§‹ä¸‹è½½: {filename} ({self.format_size(file_size)})")

        try:
            # ä½¿ç”¨æ™®é€šçš„requestsä¸‹è½½æ–‡ä»¶ï¼ˆä¸éœ€è¦GitHub APIï¼‰
            response = requests.get(download_url, stream=True, timeout=30)
            response.raise_for_status()

            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=f"_{filename}")
            temp_path = temp_file.name

            # ä¸‹è½½æ–‡ä»¶
            total_size = int(response.headers.get("content-length", file_size))
            chunk_size = self.config.get("settings", {}).get("chunk_size", 8192)

            with tqdm(
                total=total_size, unit="B", unit_scale=True, desc=filename
            ) as pbar:
                for chunk in response.iter_content(chunk_size=chunk_size):
                    if chunk:
                        temp_file.write(chunk)
                        pbar.update(len(chunk))

            temp_file.close()
            self.logger.info(f"ä¸‹è½½å®Œæˆ: {filename}")
            return temp_path

        except Exception as e:
            self.logger.error(f"ä¸‹è½½ {filename} å¤±è´¥: {e}")
            if "temp_path" in locals():
                try:
                    os.unlink(temp_path)
                except:
                    pass
            return None

    def format_size(self, size_bytes: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        if size_bytes == 0:
            return "0B"
        size_names = ["B", "KB", "MB", "GB", "TB"]
        import math

        i = int(math.floor(math.log(size_bytes, 1024)))
        p = math.pow(1024, i)
        s = round(size_bytes / p, 2)
        return f"{s} {size_names[i]}"

    def upload_to_r2(self, local_path: str, r2_key: str, metadata: Dict = None) -> bool:
        """ä¸Šä¼ æ–‡ä»¶åˆ°R2"""
        try:
            extra_args = {}
            if metadata:
                extra_args["Metadata"] = metadata

            # è®¡ç®—æ–‡ä»¶å¤§å°
            file_size = os.path.getsize(local_path)

            self.logger.info(f"å¼€å§‹ä¸Šä¼ åˆ°R2: {r2_key} ({self.format_size(file_size)})")

            # ä¸Šä¼ æ–‡ä»¶
            with tqdm(
                total=file_size, unit="B", unit_scale=True, desc="ä¸Šä¼ è¿›åº¦"
            ) as pbar:

                def upload_callback(bytes_transferred):
                    pbar.update(bytes_transferred)

                self.r2_client.upload_file(
                    local_path,
                    self.bucket_name,
                    r2_key,
                    ExtraArgs=extra_args,
                    Callback=upload_callback,
                )

            self.logger.info(f"ä¸Šä¼ å®Œæˆ: {r2_key}")
            return True

        except Exception as e:
            self.logger.error(f"ä¸Šä¼ åˆ°R2å¤±è´¥: {e}")
            return False

    def sync_project(self, project_config: Dict) -> bool:
        """åŒæ­¥å•ä¸ªé¡¹ç›®"""
        owner = project_config["owner"]
        repo = project_config["repo"]
        asset_pattern = project_config.get("asset_pattern")
        target_path = project_config.get("target_path", f"{owner}-{repo}/")

        self.logger.info(f"å¼€å§‹åŒæ­¥é¡¹ç›®: {owner}/{repo}")

        # è·å–æœ€æ–°release
        release = self.get_latest_release(owner, repo)
        if not release:
            return False

        release_tag = release["tag_name"]
        release_name = release.get("name", release_tag)
        published_at = release.get("published_at", "")

        self.logger.info(
            f"æ‰¾åˆ°æœ€æ–°release: {release_name} ({release_tag}) - å‘å¸ƒäº {published_at}"
        )

        # è¿‡æ»¤assets
        assets = self.filter_assets(release.get("assets", []), asset_pattern)
        if not assets:
            self.logger.warning(f"æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„assets")
            if asset_pattern:
                self.logger.info(f"ä½¿ç”¨çš„è¿‡æ»¤æ¨¡å¼: {asset_pattern}")
                all_assets = release.get("assets", [])
                if all_assets:
                    self.logger.info("å¯ç”¨çš„æ–‡ä»¶:")
                    for asset in all_assets[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                        self.logger.info(f"  - {asset['name']}")
            return True

        self.logger.info(f"æ‰¾åˆ° {len(assets)} ä¸ªåŒ¹é…çš„æ–‡ä»¶")

        success_count = 0
        total_size = sum(asset.get("size", 0) for asset in assets)
        self.logger.info(f"æ€»ä¸‹è½½å¤§å°: {self.format_size(total_size)}")

        for i, asset in enumerate(assets, 1):
            filename = asset["name"]
            r2_key = f"{target_path.rstrip('/')}/{release_tag}/{filename}"

            self.logger.info(f"å¤„ç†æ–‡ä»¶ {i}/{len(assets)}: {filename}")

            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
            if self.file_exists_in_r2(r2_key):
                self.logger.info(f"æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {r2_key}")
                success_count += 1
                continue

            # ä¸‹è½½æ–‡ä»¶
            temp_path = self.download_asset(asset, target_path)
            if not temp_path:
                continue

            try:
                # å‡†å¤‡å…ƒæ•°æ®
                metadata = {
                    "project": f"{owner}/{repo}",
                    "release_tag": release_tag,
                    "release_name": release_name,
                    "asset_name": filename,
                    "download_count": str(asset.get("download_count", 0)),
                    "created_at": asset.get("created_at", ""),
                    "updated_at": asset.get("updated_at", ""),
                    "size": str(asset.get("size", 0)),
                    "sync_time": datetime.now().isoformat(),
                }

                # ä¸Šä¼ åˆ°R2
                if self.upload_to_r2(temp_path, r2_key, metadata):
                    success_count += 1
                    self.logger.info(f"âœ… æˆåŠŸåŒæ­¥: {filename}")
                else:
                    self.logger.error(f"âŒ åŒæ­¥å¤±è´¥: {filename}")

            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    os.unlink(temp_path)
                except:
                    pass

        self.logger.info(
            f"é¡¹ç›® {owner}/{repo} åŒæ­¥å®Œæˆ: {success_count}/{len(assets)} æˆåŠŸ"
        )
        return success_count == len(assets)

    def sync_all_projects(self) -> Dict[str, bool]:
        """åŒæ­¥æ‰€æœ‰é¡¹ç›®"""
        projects = self.config.get("projects", [])
        if not projects:
            self.logger.warning("é…ç½®æ–‡ä»¶ä¸­æ²¡æœ‰å®šä¹‰é¡¹ç›®")
            return {}

        # æ˜¾ç¤ºAPIé™åˆ¶ä¿¡æ¯
        rate_limit_info = self.github_client.get_rate_limit_info()
        if rate_limit_info:
            core_limit = rate_limit_info.get("rate", {})
            remaining = core_limit.get("remaining", "unknown")
            limit = core_limit.get("limit", "unknown")
            reset_time = core_limit.get("reset", 0)
            reset_datetime = (
                datetime.fromtimestamp(reset_time) if reset_time else "unknown"
            )

            self.logger.info(
                f"GitHub API é™åˆ¶: {remaining}/{limit}ï¼Œé‡ç½®æ—¶é—´: {reset_datetime}"
            )

        results = {}

        for i, project in enumerate(projects, 1):
            project_name = f"{project['owner']}/{project['repo']}"
            self.logger.info(f"\n{'=' * 60}")
            self.logger.info(f"åŒæ­¥é¡¹ç›® {i}/{len(projects)}: {project_name}")
            self.logger.info(f"{'=' * 60}")

            try:
                results[project_name] = self.sync_project(project)
            except Exception as e:
                self.logger.error(f"åŒæ­¥é¡¹ç›® {project_name} æ—¶å‡ºç°å¼‚å¸¸: {e}")
                results[project_name] = False

            # é¡¹ç›®é—´ç¨ä½œå»¶è¿Ÿï¼Œé¿å…è¿‡äºé¢‘ç¹çš„APIè¯·æ±‚
            if i < len(projects):
                time.sleep(2)

        return results

    def generate_report(self, results: Dict[str, bool]):
        """ç”ŸæˆåŒæ­¥æŠ¥å‘Š"""
        total = len(results)
        success = sum(1 for v in results.values() if v)
        failed = total - success

        print("\n" + "=" * 60)
        print("ğŸ“Š åŒæ­¥æŠ¥å‘Š")
        print("=" * 60)
        print(f"ğŸ“ˆ æ€»é¡¹ç›®æ•°: {total}")
        print(f"âœ… æˆåŠŸ: {success}")
        print(f"âŒ å¤±è´¥: {failed}")
        print(
            f"ğŸ“Š æˆåŠŸç‡: {success / total * 100:.1f}%" if total > 0 else "ğŸ“Š æˆåŠŸç‡: 0%"
        )
        print("-" * 60)

        for project, status in results.items():
            status_text = "âœ… æˆåŠŸ" if status else "âŒ å¤±è´¥"
            print(f"{project}: {status_text}")

        print("=" * 60)

        # æ˜¾ç¤ºAPIä½¿ç”¨æƒ…å†µ
        rate_limit_info = self.github_client.get_rate_limit_info()
        if rate_limit_info:
            core_limit = rate_limit_info.get("rate", {})
            used = core_limit.get("limit", 0) - core_limit.get("remaining", 0)
            limit = core_limit.get("limit", 0)
            print(f"ğŸ”— GitHub API ä½¿ç”¨: {used}/{limit}")
            print("=" * 60)


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(
        description="GitHub Release to Cloudflare R2 åŒæ­¥å·¥å…·"
    )
    parser.add_argument("--config", "-c", default="config.yaml", help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--project", "-p", help="åªåŒæ­¥æŒ‡å®šé¡¹ç›® (æ ¼å¼: owner/repo)")
    parser.add_argument("--schedule", "-s", action="store_true", help="å¯åŠ¨è°ƒåº¦å™¨")
    parser.add_argument(
        "--check-limits", action="store_true", help="æ£€æŸ¥GitHub APIé™åˆ¶"
    )

    args = parser.parse_args()

    # åˆ›å»ºåŒæ­¥å™¨
    syncer = ReleaseSync(args.config)

    if args.check_limits:
        # æ£€æŸ¥APIé™åˆ¶
        rate_limit_info = syncer.github_client.get_rate_limit_info()
        if rate_limit_info:
            core_limit = rate_limit_info.get("rate", {})
            print("GitHub API é™åˆ¶ä¿¡æ¯:")
            print(f"  é™åˆ¶: {core_limit.get('limit', 'unknown')}")
            print(f"  å‰©ä½™: {core_limit.get('remaining', 'unknown')}")
            print(f"  é‡ç½®æ—¶é—´: {datetime.fromtimestamp(core_limit.get('reset', 0))}")
        else:
            print("æ— æ³•è·å–APIé™åˆ¶ä¿¡æ¯")
        return

    if args.schedule:
        # è°ƒåº¦å™¨æ¨¡å¼
        from scheduler import TaskScheduler
        from notifications import NotificationHandler

        notification_handler = NotificationHandler(syncer.config)
        scheduler = TaskScheduler(syncer.config, syncer.sync_all_projects)
        scheduler.set_notification_handler(notification_handler)
        scheduler.start()

    elif args.project:
        # åŒæ­¥å•ä¸ªé¡¹ç›®
        owner, repo = args.project.split("/")
        project_config = None

        for project in syncer.config.get("projects", []):
            if project["owner"] == owner and project["repo"] == repo:
                project_config = project
                break

        if not project_config:
            print(f"åœ¨é…ç½®æ–‡ä»¶ä¸­æœªæ‰¾åˆ°é¡¹ç›®: {args.project}")
            sys.exit(1)

        success = syncer.sync_project(project_config)
        print(f"é¡¹ç›® {args.project} åŒæ­¥{'æˆåŠŸ' if success else 'å¤±è´¥'}")
    else:
        # åŒæ­¥æ‰€æœ‰é¡¹ç›®
        results = syncer.sync_all_projects()
        syncer.generate_report(results)


if __name__ == "__main__":
    main()
